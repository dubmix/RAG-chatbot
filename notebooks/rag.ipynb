{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_FOLDER = Path(\"../chromadb/data\")\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader, SeleniumURLLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# website = \"https://hackernoon.com/vector-databases-getting-started-with-chromadb-and-more\"\n",
    "\n",
    "# def load_document(loader_class, website_url):\n",
    "#    loader = loader_class([website_url])\n",
    "#    return loader.load()\n",
    "\n",
    "# wb_loader_doc = load_document(WebBaseLoader, website)\n",
    "# wb_loader_doc[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium_loader_doc = load_document(SeleniumURLLoader, website)\n",
    "# selenium_loader_doc[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(selenium_loader_doc)\n",
    "# splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEARTBEAT: 1737548230942146000\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "print(\"HEARTBEAT:\", client.heartbeat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY, model_name=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "md_files = list(DATA_FOLDER.glob(\"*.md\"))\n",
    "\n",
    "\n",
    "def extract_sections(file_path: Path) -> list[dict]:\n",
    "    pattern = re.compile(r\"(#\\S+)(.*?)(?=(#\\S+)|\\Z)\", re.DOTALL)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    sections = []\n",
    "    for match in pattern.finditer(content):\n",
    "        section = {\"title\": match.group(1).strip(), \"content\": match.group(2).strip()}\n",
    "        sections.append(section)\n",
    "    return sections\n",
    "\n",
    "\n",
    "data = []\n",
    "for md_file in md_files:\n",
    "    file_data = extract_sections(md_file)\n",
    "    data.append(file_data)\n",
    "\n",
    "documents = []\n",
    "for entry in data:\n",
    "    for item in entry:\n",
    "        if item[\"title\"] == \"#Text\":\n",
    "            text_content = item[\"content\"]\n",
    "        elif item[\"title\"] == \"#Article\":\n",
    "            source = item[\"content\"]\n",
    "    document = f\"{text_content} Source: {source}\"\n",
    "    documents.append(document)\n",
    "\n",
    "document_ids = list(map(lambda tup: f\"id{tup[0]}\", enumerate(documents)))\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='asylumineurope' id=UUID('4a70b0ac-5a28-4731-8d8e-2b1e6dd10ffe') metadata=None tenant=None database=None\n"
     ]
    }
   ],
   "source": [
    "# collection = client.get_or_create_collection(name=\"asylumineurope\", embedding_function=openai_ef)\n",
    "# print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(id=5e8409c8-34a3-459d-b660-e3f9d791a63e, name=test_collection)\n"
     ]
    }
   ],
   "source": [
    "collection = client.get_or_create_collection(name=\"test_collection\", embedding_function=openai_ef)\n",
    "print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.add(documents=documents, ids=document_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id0', 'id1', 'id2', 'id3', 'id4', 'id5']\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"P-A studied Business Administration in Aix-en-Provence. He has an assosciate degree.\",\n",
    "    \"P-A enjoys Asian food a lot at the moment. Especially hand-pulled noodles.\",\n",
    "    \"P-A works at Signavio.NEXT, the innovation team at SAP Signavio.\",\n",
    "    \"P-A also studied ICT at 42 Berlin.\",\n",
    "    \"P-A learns Mandarin on Duolingo, after finishing the Portuguese course.\",\n",
    "    \"P-A is 31 years old.\",\n",
    "]\n",
    "\n",
    "document_ids = list(map(lambda tup: f\"id{tup[0]}\", enumerate(documents)))\n",
    "\n",
    "documents_with_ids = [(f\"id{index}\", doc) for index, doc in enumerate(documents)]\n",
    "print(document_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(documents=documents, ids=document_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id0', 'id1']],\n",
       " 'distances': None,\n",
       " 'embeddings': None,\n",
       " 'metadatas': None,\n",
       " 'documents': [['P-A studied Business Administration in Aix-en-Provence. He has an assosciate degree.',\n",
       "   'P-A enjoys Asian food a lot at the moment. Especially hand-pulled noodles.']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['documents']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(query_texts=[\"question\"], n_results=2, include=[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the following code does not work because the embeddings cannot be retrieved\n",
    "\n",
    "# vectordb = Chroma(persist_directory=\"../src/chromadb/chroma_data\", collection_name=\"test_collection\", embedding_function=openai_ef)\n",
    "# vectordb._collection.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     Answer the question based only on the following context:\n",
    "#     Context: {context}\n",
    "#     Question: {question}\n",
    "#     \"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = Chroma.from_texts([\"PA is working at SAP\",\n",
    "#                                 \"PA also participates in a non-profit project\",\n",
    "#                                 \"PA's fav pokemon is Snorlax\",\n",
    "#                                 \"PA likes tacos\"], embedding=OpenAIEmbeddings())\n",
    "# vectorstore.persist()\n",
    "# retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_chain = (\n",
    "#     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = rag_chain.invoke(\"What can you tell me about PA?\")\n",
    "# response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
